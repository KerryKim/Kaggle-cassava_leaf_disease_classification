{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from tensor to numpy function\n",
    "fn_tonumpy = lambda x: x.to('cpu').detach().numpy()\n",
    "\n",
    "## 리스트 펼치기 함수\n",
    "def flatten(lst):\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        result.extend(item)\n",
    "    return result\n",
    "\n",
    "## 제출파일 저장하기\n",
    "def save_submission(data_dir, result_dir, pred, epoch, batch):\n",
    "    submission = pd.DataFrame()\n",
    "    df = pd.read_csv('./data/val_images_relabeled/fold4.csv')\n",
    "    submission['image_id'] =  df['image_id']\n",
    "    submission['label'] = pred\n",
    "    submission.to_csv('./data/val_images_relabeled/result/submission_f4.csv', index=False)\n",
    "\n",
    "\n",
    "## 네트워크 불러오기\n",
    "def load(ckpt_dir, net, optim):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "    dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    #epoch.load_state_dict(dict_model['epoch'])\n",
    "    #epoch = int(ckpt_lst[-1].split('epoch')[1].split('_batch')[0])\n",
    "\n",
    "    return net, optim#, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, data_dir, img_x, img_y, transform=None):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.img_x = img_x\n",
    "        self.img_y = img_y\n",
    "        self.transform = transform\n",
    "\n",
    "        lst_label = list(df['label'])\n",
    "        lst_input = list(x for x in df.image_id.values)\n",
    "        self.lst_label = lst_label\n",
    "        self.lst_input = lst_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.lst_label[index]\n",
    "        input = cv2.imread(os.path.join(self.data_dir, self.lst_input[index]), cv2.IMREAD_COLOR)\n",
    "        input = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)  # result of input shape is y,x,c\n",
    "\n",
    "        if self.transform:\n",
    "            input = self.transform(image=input)['image']\n",
    "\n",
    "        data = {'input': input, 'label' : label}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "##\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, network, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(network, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def transform_test(img_x, img_y):\n",
    "    return A.Compose([\n",
    "            A.RandomResizedCrop(img_x, img_y),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "#             A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "#             A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)], p=1.)\n",
    "\n",
    "def dataloader_test(df, data_dir, img_x, img_y, batch_size):\n",
    "    dataset_test = TestDataset(df=df, data_dir=data_dir, img_x=img_x, img_y=img_y, transform=transform_test(img_x, img_y))\n",
    "    loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    num_data_test = len(dataset_test)\n",
    "    num_batch_test = np.ceil(num_data_test / batch_size)\n",
    "\n",
    "    return loader_test, num_batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_digit(output, batch_size):\n",
    "    np_output = fn_tonumpy(output)\n",
    "    lst_output = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        nb_output = np.argmax(np_output[i, :])\n",
    "        lst_output.append(nb_output)\n",
    "\n",
    "    return lst_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args):\n",
    "    # hyperparameters\n",
    "    img_x = args.img_x\n",
    "    img_y = args.img_y\n",
    "\n",
    "    lr = args.lr\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    num_epoch = args.num_epoch\n",
    "\n",
    "    data_dir = args.data_dir\n",
    "    ckpt_dir = args.ckpt_dir\n",
    "    result_dir = args.result_dir\n",
    "\n",
    "    network = args.network\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "##\n",
    "    print(\"Test start ... \")\n",
    "    df = pd.read_csv('./data/val_images_relabeled/fold4.csv')\n",
    "\n",
    "    loader_test, num_batch_test = dataloader_test(df=df, data_dir=data_dir, img_x=img_x, img_y=img_y, batch_size=batch_size)\n",
    "    net = CassvaImgClassifier(network, df.label.nunique(), pretrained=False).to(device)\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-6)\n",
    "    net, optim = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "    #used_epoch = [6, 7, 8, 9]  if test use rnd_epochs, it can have weights for each iteration.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        st_iter = 0\n",
    "        tta = 1\n",
    "        lst_pred = []\n",
    "\n",
    "        acc_epoch_test = 0\n",
    "\n",
    "        for batch, data in enumerate(loader_test, 1):\n",
    "            # forward pass\n",
    "            label = data['label'].to(device).long()\n",
    "            input = data['input'].to(device).float()\n",
    "\n",
    "            output = net(input)\n",
    "\n",
    "            pred = torch.argmax(output, dim=1).cpu().detach().numpy()\n",
    "            lst_pred.append(pred)  \n",
    "            \n",
    "            label = label.cpu().detach().numpy()\n",
    "            acc_batch_test = accuracy_score(label, pred)\n",
    "            acc_epoch_test += acc_batch_test\n",
    "\n",
    "        \n",
    "        test_acc = (acc_epoch_test / num_batch_test)\n",
    "        prediction = flatten(lst_pred)\n",
    "        \n",
    "        print(test_acc)\n",
    "#         print(prediction)\n",
    "\n",
    "\n",
    "        # submission\n",
    "        save_submission(data_dir=data_dir, result_dir=result_dir, pred=prediction, epoch=num_epoch, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test start ... \n",
      "0.8759345794392523\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "## Parser 생성하기\n",
    "parser = argparse.ArgumentParser(description=\"Cassava Leaf Disease Classification\",\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"--mode\", default=\"test\", choices=[\"train\", \"test\"], type=str, dest=\"mode\")\n",
    "parser.add_argument(\"--train_continue\", default=\"off\", choices=[\"on\", \"off\"], type=str, dest=\"train_continue\")\n",
    "\n",
    "parser.add_argument(\"--seed\", default=719, type=int, dest=\"seed\")\n",
    "parser.add_argument(\"--img_x\", default=512, type=int, dest=\"img_x\")\n",
    "parser.add_argument(\"--img_y\", default=512, type=int, dest=\"img_y\")\n",
    "\n",
    "parser.add_argument(\"--lr\", default=1e-4, type=float, dest=\"lr\")\n",
    "parser.add_argument(\"--num_fold\", default=10, type=int, dest=\"num_fold\")\n",
    "parser.add_argument(\"--num_epoch\", default=10, type=int, dest=\"num_epoch\")\n",
    "parser.add_argument(\"--batch_size\", default=4, type=int, dest=\"batch_size\")\n",
    "\n",
    "parser.add_argument(\"--cutmix\", default=False, choices=[True, False], type=bool, dest=\"cutmix\")\n",
    "parser.add_argument(\"--fmix\", default=False, choices=[True, False], type=bool, dest=\"fmix\")\n",
    "\n",
    "parser.add_argument(\"--label_smooth\", default=False, choices=[True, False], type=bool, dest=\"label_smooth\")\n",
    "parser.add_argument(\"--swa\", default=False, choices=[True, False], type=bool, dest=\"swa\")\n",
    "\n",
    "parser.add_argument(\"--data_dir\", default=\"./data/val_images_relabeled/fold4\", type=str, dest=\"data_dir\")\n",
    "parser.add_argument(\"--ckpt_dir\", default=\"./data/val_images_relabeled/checkpoint\", type=str, dest=\"ckpt_dir\")\n",
    "parser.add_argument(\"--result_dir\", default=\"./data/val_images_relabeled/result\", type=str, dest=\"result_dir\")\n",
    "\n",
    "parser.add_argument(\"--network\", default=\"tf_efficientnet_b4_ns\", type=str, dest=\"network\")\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "##\n",
    "if __name__ == \"__main__\":\n",
    "    # random seed\n",
    "    def seed_everything(seed):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    seed = args.seed\n",
    "    seed_everything(seed)\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        train(args)\n",
    "    elif args.mode == \"test\":\n",
    "        test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8764018691588785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8953271028037383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8968847352024921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8994548286604361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cldc]",
   "language": "python",
   "name": "conda-env-cldc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
