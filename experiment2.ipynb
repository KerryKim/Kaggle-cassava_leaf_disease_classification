{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train_images_relabeled/fold0/100042118.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a23cb5b6eaf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/train_images/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data/train_images_relabeled/fold{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cldc/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train_images_relabeled/fold0/100042118.jpg'"
     ]
    }
   ],
   "source": [
    "# Fold에 파일저장\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "num_fold = 5\n",
    "seed = 719\n",
    "\n",
    "Kfold = StratifiedKFold(n_splits=num_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(Kfold.split(np.arange(df.shape[0]), df.label.values)):\n",
    "    val = df.loc[val_idx, :]['image_id'].values\n",
    "    for i, val in enumerate(val):\n",
    "        #shutil.copyfile('./data/train_images/{}'.format(val), './data/train_images_relabeled/fold{}/{}'.format(fold, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280\n",
      "4280\n",
      "4279\n",
      "4279\n",
      "4279\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(Kfold.split(np.arange(df.shape[0]), df.label.values)):\n",
    "    print(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(Kfold.split(np.arange(df.shape[0]), df.label.values)):\n",
    "    val = df.loc[val_idx, :]\n",
    "    val.to_csv('./fold{}.csv'.format(fold), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             image_id  label\n",
      "2       100042118.jpg      1\n",
      "15     1003218714.jpg      2\n",
      "16     1003298598.jpg      3\n",
      "21     1004163647.jpg      3\n",
      "25     1004826518.jpg      2\n",
      "...               ...    ...\n",
      "21383   997161074.jpg      3\n",
      "21385   997289539.jpg      2\n",
      "21393   999329392.jpg      3\n",
      "21394   999474432.jpg      1\n",
      "21396   999998473.jpg      4\n",
      "\n",
      "[4280 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(Kfold.split(np.arange(df.shape[0]), df.label.values)):\n",
    "    val = df.loc[val_idx, :]\n",
    "    print(val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [[0.1, 0.2, 0.6, 0.1], [0.2, 0.4, 0.1, 0.3]]\n",
    "\n",
    "pred_1 = np.mean(pred, axis=0)\n",
    "\n",
    "if max(pred_1) < 0.9:\n",
    "    pred_1 = [np.nan]\n",
    "    \n",
    "pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-244a4231b8b1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-244a4231b8b1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a= [[0.00303988 0.00445192 0.14309295 0.00346654 0.09594872]]\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a= [[0.00303988 0.00445192 0.14309295 0.00346654 0.09594872]]\n",
    "a = list(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "## from tensor to numpy function\n",
    "fn_tonumpy = lambda x: x.to('cpu').detach().numpy()\n",
    "\n",
    "## 리스트 펼치기 함수\n",
    "def flatten(lst):\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        result.extend(item)\n",
    "    return result\n",
    "\n",
    "## 제출파일 저장하기\n",
    "def save_submission(data_dir, result_dir, pred, epoch, batch):\n",
    "    submission = pd.DataFrame()\n",
    "    submission['image_id'] = list(os.listdir(data_dir))\n",
    "    submission['label'] = pred\n",
    "    submission.to_csv('./result/submission.csv', index=False)\n",
    "\n",
    "\n",
    "## 네트워크 불러오기\n",
    "def load(ckpt_dir, net, optim):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "    dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    #epoch.load_state_dict(dict_model['epoch'])\n",
    "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('_batch')[0])\n",
    "\n",
    "    return net, optim, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "##\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, img_x, img_y, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_x = img_x\n",
    "        self.img_y = img_y\n",
    "        self.transform = transform\n",
    "\n",
    "        lst_input = os.listdir(self.data_dir)\n",
    "        self.lst_input = lst_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = cv2.imread(os.path.join(self.data_dir, self.lst_input[index]), cv2.IMREAD_COLOR)\n",
    "        input = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)  # result of input shape is y,x,c\n",
    "\n",
    "        if self.transform:\n",
    "            input = self.transform(image=input)['image']\n",
    "\n",
    "        data = {'input': input}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "##\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, network, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(network, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def transform_test(img_x, img_y):\n",
    "    return A.Compose([\n",
    "            A.RandomResizedCrop(img_x, img_y),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)], p=1.)\n",
    "\n",
    "def dataloader_test(data_dir, img_x, img_y, batch_size):\n",
    "    dataset_test = TestDataset(data_dir=data_dir, img_x=img_x, img_y=img_y, transform=transform_test(img_x, img_y))\n",
    "    loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    num_data_test = len(dataset_test)\n",
    "    num_batch_test = np.ceil(num_data_test / batch_size)\n",
    "\n",
    "    return loader_test, num_batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args):\n",
    "    # hyperparameters\n",
    "    img_x = args.img_x\n",
    "    img_y = args.img_y\n",
    "\n",
    "    lr = args.lr\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    num_epoch = args.num_epoch\n",
    "\n",
    "    data_dir = args.data_dir\n",
    "    ckpt_dir = args.ckpt_dir\n",
    "    result_dir = args.result_dir\n",
    "\n",
    "    network = args.network\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "##\n",
    "    print(\"Test start ... \")\n",
    "    df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "    loader_test, num_batch_test = dataloader_test(data_dir=data_dir, img_x=img_x, img_y=img_y, batch_size=batch_size)\n",
    "    net = CassvaImgClassifier(network, df.label.nunique(), pretrained=False).to(device)\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-6)\n",
    "    net, optim, epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "    #used_epoch = [6, 7, 8, 9]  if test use rnd_epochs, it can have weights for each iteration.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        st_iter = 0\n",
    "        tta = 1\n",
    "        pred_tta = []\n",
    "\n",
    "        for iter in range(st_iter + 1, tta + 1):\n",
    "            pred_epoch = []\n",
    "\n",
    "            for batch, data in enumerate(loader_test, 1):\n",
    "                # forward pass\n",
    "                input = data['input'].to(device)\n",
    "\n",
    "                output = net(input)\n",
    "                output = torch.softmax(output, dim=1).cpu().detach().numpy()\n",
    "\n",
    "                print(\"TTA ITERATION: {}/{} | \".format(iter, tta), \"BATCH: %04d / %04d\" % (batch, num_batch_test))\n",
    "\n",
    "                pred_epoch += [output]\n",
    "                \n",
    "\n",
    "            pred_epoch = np.concatenate(pred_epoch, axis=0)\n",
    "            pred_tta += [pred_epoch/tta]\n",
    "            \n",
    "        pred = (np.mean(pred_tta, axis=0)).argmax(axis=1)\n",
    "        # submission\n",
    "        if tta % iter == 0:\n",
    "            save_submission(data_dir=data_dir, result_dir=result_dir, pred=pred, epoch=num_epoch, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test start ... \n",
      "TTA ITERATION: 1/1 |  BATCH: 0001 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0002 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0003 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0004 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0005 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0006 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0007 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0008 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0009 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0010 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0011 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0012 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0013 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0014 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0015 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0016 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0017 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0018 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0019 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0020 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0021 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0022 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0023 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0024 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0025 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0026 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0027 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0028 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0029 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0030 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0031 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0032 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0033 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0034 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0035 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0036 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0037 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0038 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0039 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0040 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0041 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0042 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0043 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0044 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0045 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0046 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0047 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0048 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0049 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0050 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0051 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0052 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0053 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0054 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0055 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0056 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0057 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0058 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0059 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0060 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0061 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0062 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0063 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0064 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0065 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0066 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0067 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0068 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0069 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0070 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0071 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0072 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0073 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0074 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0075 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0076 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0077 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0078 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0079 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0080 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0081 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0082 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0083 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0084 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0085 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0086 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0087 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0088 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0089 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0090 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0091 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0092 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0093 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0094 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0095 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0096 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0097 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0098 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0099 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0100 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0101 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0102 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0103 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0104 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0105 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0106 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0107 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0108 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0109 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0110 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0111 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0112 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0113 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0114 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0115 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0116 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0117 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0118 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0119 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0120 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0121 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0122 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0123 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0124 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0125 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0126 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0127 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0128 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0129 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0130 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0131 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0132 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0133 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0134 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0135 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0136 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0137 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0138 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0139 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0140 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0141 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0142 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0143 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0144 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0145 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0146 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0147 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0148 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0149 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0150 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0151 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0152 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0153 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0154 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0155 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0156 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0157 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0158 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0159 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0160 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0161 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0162 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0163 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0164 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0165 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0166 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0167 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0168 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0169 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0170 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0171 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0172 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0173 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0174 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0175 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0176 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0177 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0178 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0179 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0180 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0181 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0182 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0183 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0184 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0185 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0186 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0187 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0188 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0189 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0190 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0191 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0192 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0193 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0194 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0195 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0196 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0197 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0198 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0199 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0200 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0201 / 0535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA ITERATION: 1/1 |  BATCH: 0202 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0203 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0204 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0205 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0206 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0207 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0208 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0209 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0210 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0211 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0212 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0213 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0214 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0215 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0216 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0217 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0218 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0219 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0220 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0221 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0222 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0223 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0224 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0225 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0226 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0227 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0228 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0229 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0230 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0231 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0232 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0233 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0234 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0235 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0236 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0237 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0238 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0239 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0240 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0241 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0242 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0243 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0244 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0245 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0246 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0247 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0248 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0249 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0250 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0251 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0252 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0253 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0254 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0255 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0256 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0257 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0258 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0259 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0260 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0261 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0262 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0263 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0264 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0265 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0266 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0267 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0268 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0269 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0270 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0271 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0272 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0273 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0274 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0275 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0276 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0277 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0278 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0279 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0280 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0281 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0282 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0283 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0284 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0285 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0286 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0287 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0288 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0289 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0290 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0291 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0292 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0293 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0294 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0295 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0296 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0297 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0298 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0299 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0300 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0301 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0302 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0303 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0304 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0305 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0306 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0307 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0308 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0309 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0310 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0311 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0312 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0313 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0314 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0315 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0316 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0317 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0318 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0319 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0320 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0321 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0322 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0323 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0324 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0325 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0326 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0327 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0328 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0329 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0330 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0331 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0332 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0333 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0334 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0335 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0336 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0337 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0338 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0339 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0340 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0341 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0342 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0343 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0344 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0345 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0346 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0347 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0348 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0349 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0350 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0351 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0352 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0353 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0354 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0355 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0356 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0357 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0358 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0359 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0360 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0361 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0362 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0363 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0364 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0365 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0366 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0367 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0368 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0369 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0370 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0371 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0372 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0373 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0374 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0375 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0376 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0377 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0378 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0379 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0380 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0381 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0382 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0383 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0384 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0385 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0386 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0387 / 0535\n",
      "TTA ITERATION: 1/1 |  BATCH: 0388 / 0535\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "## Parser 생성하기\n",
    "parser = argparse.ArgumentParser(description=\"Cassava Leaf Disease Classification\",\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"--mode\", default=\"test\", choices=[\"train\", \"test\"], type=str, dest=\"mode\")\n",
    "parser.add_argument(\"--train_continue\", default=\"off\", choices=[\"on\", \"off\"], type=str, dest=\"train_continue\")\n",
    "\n",
    "parser.add_argument(\"--seed\", default=719, type=int, dest=\"seed\")\n",
    "parser.add_argument(\"--img_x\", default=512, type=int, dest=\"img_x\")\n",
    "parser.add_argument(\"--img_y\", default=512, type=int, dest=\"img_y\")\n",
    "\n",
    "parser.add_argument(\"--lr\", default=1e-4, type=float, dest=\"lr\")\n",
    "parser.add_argument(\"--num_fold\", default=10, type=int, dest=\"num_fold\")\n",
    "parser.add_argument(\"--num_epoch\", default=10, type=int, dest=\"num_epoch\")\n",
    "parser.add_argument(\"--batch_size\", default=8, type=int, dest=\"batch_size\")\n",
    "\n",
    "parser.add_argument(\"--cutmix\", default=False, choices=[True, False], type=bool, dest=\"cutmix\")\n",
    "parser.add_argument(\"--fmix\", default=False, choices=[True, False], type=bool, dest=\"fmix\")\n",
    "\n",
    "parser.add_argument(\"--label_smooth\", default=False, choices=[True, False], type=bool, dest=\"label_smooth\")\n",
    "parser.add_argument(\"--swa\", default=False, choices=[True, False], type=bool, dest=\"swa\")\n",
    "\n",
    "parser.add_argument(\"--data_dir\", default=\"./data/val_images_relabeled/fold0\", type=str, dest=\"data_dir\")\n",
    "parser.add_argument(\"--ckpt_dir\", default=\"./checkpoint\", type=str, dest=\"ckpt_dir\")\n",
    "parser.add_argument(\"--result_dir\", default=\"./result\", type=str, dest=\"result_dir\")\n",
    "\n",
    "parser.add_argument(\"--network\", default=\"tf_efficientnet_b4_ns\", type=str, dest=\"network\")\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "##\n",
    "if __name__ == \"__main__\":\n",
    "    # random seed\n",
    "    def seed_everything(seed):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    seed = args.seed\n",
    "    seed_everything(seed)\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        train(args)\n",
    "    elif args.mode == \"test\":\n",
    "        test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cldc]",
   "language": "python",
   "name": "conda-env-cldc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
