{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, data_dir, img_x, img_y, transform=None):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.img_x = img_x\n",
    "        self.img_y = img_y\n",
    "        self.transform = transform\n",
    "        lst_label = list(df['label'])\n",
    "        lst_input = list(x for x in df.image_id.values)\n",
    "        self.lst_label = lst_label\n",
    "        self.lst_input = lst_input\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_label)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.lst_label[index]\n",
    "        input = cv2.imread(os.path.join(self.data_dir, self.lst_input[index]), cv2.IMREAD_COLOR)\n",
    "        input = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)  # result of input shape is y,x,c\n",
    "\n",
    "        if self.transform:\n",
    "            input = self.transform(image=input)['image']\n",
    "\n",
    "        data = {'input' : input, 'label' : label}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train(img_x, img_y):\n",
    "    return A.Compose([A.RandomResizedCrop(img_x, img_y),\n",
    "                      A.Transpose(p=0.5),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.VerticalFlip(p=0.5),\n",
    "                      A.ShiftScaleRotate(p=0.5),\n",
    "                      A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                      A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                      A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "                      A.CoarseDropout(p=0.5), A.Cutout(p=0.5),ToTensorV2(p=1.0)], p=1.)\n",
    "\n",
    "\n",
    "def transform_val(img_x, img_y):\n",
    "    return A.Compose([A.CenterCrop(img_x, img_y, p=1.),\n",
    "                      A.Resize(img_x, img_y),\n",
    "                      A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),ToTensorV2(p=1.0)], p=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "##\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, network, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(network, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataloader_train(df, data_dir, trn_idx, val_idx, img_x, img_y, batch_size):\n",
    "    train = df.loc[trn_idx, :].reset_index(drop=True)\n",
    "    val = df.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "    dataset_train = TrainDataset(df=train, data_dir=data_dir, img_x=img_x, img_y=img_y, transform=transform_train(img_x, img_y))\n",
    "    loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    dataset_val = TrainDataset(df=val, data_dir=data_dir, img_x=img_x, img_y=img_y, transform=transform_val(img_x, img_y))\n",
    "    loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    num_data_train = len(dataset_train)\n",
    "    num_data_val = len(dataset_val)\n",
    "\n",
    "    num_batch_train = np.ceil(num_data_train / batch_size)\n",
    "    num_batch_val = np.ceil(num_data_val / batch_size)\n",
    "\n",
    "    return loader_train, loader_val, num_batch_train, num_batch_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # hyperparameters\n",
    "    train_continue = args.train_continue\n",
    "    seed = args.seed\n",
    "\n",
    "    img_x = args.img_x\n",
    "    img_y = args.img_y\n",
    "\n",
    "    lr = args.lr\n",
    "    num_fold = args.num_fold\n",
    "    num_epoch = args.num_epoch\n",
    "    batch_size = args.batch_size\n",
    "    \n",
    "    data_dir = args.data_dir\n",
    "    ckpt_dir = args.ckpt_dir\n",
    "\n",
    "    network = args.network\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    ##\n",
    "    df = pd.read_csv('./data/train.csv')\n",
    "    Kfold = StratifiedKFold(n_splits=num_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(Kfold.split(np.arange(df.shape[0]), df.label.values)):\n",
    "        if fold > 0:\n",
    "            break\n",
    "\n",
    "        print(\"Training start ... \")\n",
    "        print(\"DATE: {} | \".format(datetime.now().strftime(\"%m.%d-%H:%M\")), \"KFOLD: {}/{}\".format(fold, num_fold))\n",
    "\n",
    "        loader_train, loader_val, num_batch_train, num_batch_val = \\\n",
    "            dataloader_train(df, data_dir, trn_idx, val_idx, img_x, img_y, batch_size)\n",
    "\n",
    "        net = CassvaImgClassifier(network, df.label.nunique(), pretrained=True).to(device)\n",
    "        fn_loss = nn.CrossEntropyLoss().to(device) \n",
    "        optim = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-6)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        ##\n",
    "        st_epoch = 0\n",
    "        best_loss = 1e20\n",
    "        best_acc = 0\n",
    "        early_stop_patience = 0\n",
    "\n",
    "        if train_continue == \"on\":\n",
    "            net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "        train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "        for epoch in range(st_epoch + 1, num_epoch + 1):\n",
    "            net.train()\n",
    "            loss_arr = []  # loss array for one batch\n",
    "\n",
    "            # loss/accuracy for one epoch\n",
    "            loss_epoch_train = 0\n",
    "            acc_epoch_train = 0\n",
    "\n",
    "            # cuda device로 보내는 부분의 용량을 줄이기 위해서 long과 float을 해줫더니 배치도 늘어나고 쿠다도 들어감\n",
    "            \n",
    "            for batch, data in enumerate(loader_train, 1):\n",
    "                # forward pass\n",
    "                label = data['label'].to(device).long()\n",
    "                input = data['input'].to(device).float()\n",
    "                \n",
    "\n",
    "                with autocast():\n",
    "                    output = net(input)\n",
    "                    print(output)\n",
    "                    break\n",
    "                    loss = fn_loss(output, label)\n",
    "                    #print(loss)\n",
    "                    optim.zero_grad()\n",
    "\n",
    "                # backward pass\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # loss.backward()\n",
    "                # optim.step()\n",
    "\n",
    "                loss_arr += [loss.item()]\n",
    "                loss_batch_train = np.mean(loss_arr)\n",
    "                loss_epoch_train += loss_batch_train\n",
    "\n",
    "                output = torch.argmax(output, dim=1).cpu().detach().numpy()\n",
    "                label = label.cpu().detach().numpy()\n",
    "                acc_batch_train = accuracy_score(label, output)\n",
    "                acc_epoch_train += acc_batch_train\n",
    "\n",
    "            train_loss.append(loss_epoch_train / num_batch_train)\n",
    "            train_acc.append(acc_epoch_train / num_batch_train)\n",
    "\n",
    "            \n",
    "            scheduler.step(train_loss[-1])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                loss_arr = []\n",
    "\n",
    "                loss_epoch_val = 0\n",
    "                acc_epoch_val = 0\n",
    "\n",
    "                for batch, data in enumerate(loader_val, 1):\n",
    "                    label = data['label'].to(device).long()\n",
    "                    input = data['input'].to(device).float()\n",
    "\n",
    "                    output = net(input)\n",
    "\n",
    "                    loss = fn_loss(output, label)\n",
    "\n",
    "                    loss_arr += [loss.item()]\n",
    "                    loss_batch_val = np.mean(loss_arr)\n",
    "                    loss_epoch_val += loss_batch_val\n",
    "\n",
    "                    output = torch.argmax(output, dim=1).cpu().detach().numpy()\n",
    "                    label = label.cpu().detach().numpy()\n",
    "                    acc_batch_val = accuracy_score(label, output)\n",
    "                    acc_epoch_val += acc_batch_val\n",
    "\n",
    "                val_loss.append(loss_epoch_val / num_batch_val)\n",
    "                val_acc.append(acc_epoch_val / num_batch_val)\n",
    "\n",
    "            scheduler.step(val_loss[-1])\n",
    "\n",
    "            print(\"DATE: {} | \".format(datetime.now().strftime(\"%m.%d-%H:%M\")), \"EPOCH: {}/{} | \".format(epoch, num_epoch),\n",
    "                  \"TRAIN_LOSS: {:4f} | \".format(train_loss[-1]),  \"TRAIN_ACC: {:4f} | \".format(train_acc[-1]),\n",
    "                  \"VAL_LOSS: {:4f} | \".format(val_loss[-1]), \"VAL_ACC: {:4f} | \".format(val_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start ... \n",
      "DATE: 01.15-17:32 |  KFOLD: 0/5\n",
      "tensor([[-0.1736, -0.0427,  0.0158,  0.0220,  0.0210],\n",
      "        [-0.1326,  0.0092,  0.0056, -0.0325,  0.0194],\n",
      "        [-0.0288, -0.0897, -0.0828, -0.1086,  0.1046],\n",
      "        [ 0.0036, -0.0721, -0.0434, -0.0005, -0.1387],\n",
      "        [ 0.1370,  0.0578,  0.0423,  0.1295,  0.1976],\n",
      "        [ 0.1209,  0.0155,  0.0259,  0.0798,  0.0057],\n",
      "        [-0.0374,  0.0362, -0.0069, -0.0933, -0.0832],\n",
      "        [-0.1527, -0.0215, -0.0057, -0.0333, -0.1107]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-afc63634ee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-280bd1e1294c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                     \u001b[0mloss_arr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                     \u001b[0mloss_batch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mloss_epoch_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_batch_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 라이브러리 추가하기\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "\n",
    "## Parser 생성하기\n",
    "parser = argparse.ArgumentParser(description=\"Cassava Leaf Disease Classification\",\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"--mode\", default=\"train\", choices=[\"train\", \"test\"], type=str, dest=\"mode\")\n",
    "parser.add_argument(\"--train_continue\", default=\"off\", choices=[\"on\", \"off\"], type=str, dest=\"train_continue\")\n",
    "\n",
    "parser.add_argument(\"--seed\", default=719, type=int, dest=\"seed\")\n",
    "parser.add_argument(\"--img_x\", default=512, type=int, dest=\"img_x\")\n",
    "parser.add_argument(\"--img_y\", default=512, type=int, dest=\"img_y\")\n",
    "\n",
    "parser.add_argument(\"--lr\", default=1e-4, type=float, dest=\"lr\")\n",
    "parser.add_argument(\"--num_fold\", default=5, type=int, dest=\"num_fold\")\n",
    "parser.add_argument(\"--num_epoch\", default=10, type=int, dest=\"num_epoch\")\n",
    "parser.add_argument(\"--batch_size\", default=8, type=int, dest=\"batch_size\")\n",
    "\n",
    "parser.add_argument(\"--data_dir\", default=\"./data/train_images\", type=str, dest=\"data_dir\")\n",
    "parser.add_argument(\"--ckpt_dir\", default=\"./checkpoint\", type=str, dest=\"ckpt_dir\")\n",
    "parser.add_argument(\"--result_dir\", default=\"./result\", type=str, dest=\"result_dir\")\n",
    "\n",
    "parser.add_argument(\"--network\", default=\"tf_efficientnet_b4_ns\", type=str, dest=\"network\")\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "##\n",
    "if __name__ == \"__main__\":\n",
    "    # random seed\n",
    "    def seed_everything(seed):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    seed = args.seed\n",
    "    seed_everything(seed)\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        train(args)\n",
    "    elif args.mode == \"test\":\n",
    "        test(args)\n",
    "\n",
    "# tensorboard --logdir ./log/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cldc]",
   "language": "python",
   "name": "conda-env-cldc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
